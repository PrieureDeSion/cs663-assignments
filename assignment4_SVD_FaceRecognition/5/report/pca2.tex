\title{\bf CS 663 -- Assignment 4}
\author{\emph{Dhruv Ilesh Shah, Bhavesh Thakkar and Dhanvi Sreenivasan}}
\date{}

\documentclass[11pt]{article}
\pagenumbering{gobble}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[margin=0.4in]{geometry}
\usepackage{mathtools}
\begin{document}
\maketitle

\begin{enumerate}
\setcounter{enumi}{4}
\item {\bf Consider a set of $N$ vectors $\mathcal{X} = \{\boldsymbol{x_1}, \boldsymbol{x_2}, ..., \boldsymbol{x_N}\}$ each in $\mathbb{R}^d$, with average vector $\boldsymbol{\bar{x}}$. We have seen in class that the direction $\boldsymbol{e}$ such that $\sum_{i=1}^N \|\boldsymbol{x_i}-\boldsymbol{\bar{x}}-(\boldsymbol{e} \cdot (\boldsymbol{x_i}-\boldsymbol{\bar{x}}))\boldsymbol{e}\|^2$ is minimized, is obtained by maximizing $\boldsymbol{e}^t \boldsymbol{C} \boldsymbol{e}$, where $\boldsymbol{C}$ is the covariance matrix of the vectors in $\mathcal{X}$. This vector $\boldsymbol{e}$ is the eigenvector of matrix $\boldsymbol{C}$ with the highest eigenvalue. Prove that the direction $\boldsymbol{f}$ perpendicular to $\boldsymbol{e}$ for which $\boldsymbol{f}^t \boldsymbol{C} \boldsymbol{f}$ is maximized, is the eigenvector of $\boldsymbol{C}$ with the second highest eigenvalue. For simplicity, assume that all non-zero eigenvalues of $\boldsymbol{C}$ are distinct and that $\textrm{rank}(\boldsymbol{C}) > 2$.}

{\em Solution:}
\vspace*{1em}

\hspace*{1em}We need to identify a direction $f$ that maximizes $f^TCf$, given that $f$ is perpendicular to a $e$ ($f^Te = e^Tf = 0$), where $e$ is the eigenvector of $C$ corresponding to the largest eigenvalue. We approach this problem by using the tool of Lagrange multipliers. The system constraints are as given below

\begin{equation}
\begin{split}
f^Tf &= 1 \\
f^Te &= 1
\end{split}
\end{equation}
We define $L$, the function to be optimized, as follows
\begin{equation}
\label{eq:lag-full}
L(f, \lambda, \mu) = f^TCf + \lambda f^Te + \mu(f^Tf - 1)
\end{equation}
Differentiating $L$ with respect to $f$ and setting the gradient to $0$ gives us the following relation in $(\mu, \lambda)$
\begin{equation}
\frac{\partial L(f, \lambda, \mu)}{\partial f} = L_f(f, \lambda, \mu) = 2Cf + \lambda e + 2\mu f = 0
\end{equation}
This follows from the fact that $\frac{\partial}{\partial a}a^TXa = 2Xa$ for square matrix $X$ and column vector $a$, $\frac{\partial}{\partial a}a^Ta = 2a$ for a column vector $a$ and $\frac{\partial}{\partial a}a^Tb = b$ for column vectors $a, b$.\\
\hspace*{1em} From Eqn. \ref{eq:lag-full}, we must compute $\mu, \lambda$ such that $L_f(f, \lambda, \mu) = 0$. Multiplying left with $e^T$, we get
\begin{align}
2e^TCf + \lambda e^Te + 2\mu e^Tf = 0 \\
\shortintertext{$e^te = 1,\;\;\;e^Tf = 0$}
2e^TCf + \lambda = 0 \\
\lambda = 2e^TCf = 2f^TC^Te \\
\shortintertext{Since $C$ is the covariance matrix, $C = C^T$:}
\lambda = 2f^TCe = 0
\end{align}
Thus, we have $\lambda = 0$ and hence we can compute $\mu$ from Eqn. \ref{eq:lag-full} as follows
\begin{equation}
\mu f = Cf
\end{equation}
Clearly, $f$ must be an eigen vector of $C$, with eigenvalue $\mu$. Substituting, we get $f^TCf = \mu$, and this is maximal at the largest eigenvalue (not corresponding to the eigenvalue of $e$, say $\lambda_e$ since we have $e^Tf=0$). Since $\lambda_e$ is known to be the largest eigenvalue, the $f$ maximising $f^TCf$ under the given constraints is thus the eigenvector corresponding to the second largest eigenvalue, say $\lambda_f$.

\end{enumerate}

\end{document}
